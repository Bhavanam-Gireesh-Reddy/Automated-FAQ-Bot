{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7509d59a-cb4e-4e8b-9567-9492f8552088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json # Import the json module\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader # We'll still use this for individual text entries\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import FastEmbedEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.schema import Document # Import Document for creating LangChain documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "650caa77-2b20-439d-915d-7f0e60b3665d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b7cbfc-d8ce-4f60-b228-caef2963de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Load Your FAQ Data (Updated for your JSON structure) ---\n",
    "faq_data = []\n",
    "try:\n",
    "    with open('Ecommerce_FAQ_Chatbot_dataset.json', 'r', encoding='utf-8') as f:\n",
    "        full_json_content = json.load(f)\n",
    "        # Access the list of questions using the 'questions' key\n",
    "        json_questions_list = full_json_content.get('questions', [])\n",
    "\n",
    "        if not json_questions_list:\n",
    "            print(\"Warning: 'questions' key not found or is empty in faq.json.\")\n",
    "\n",
    "        for item in json_questions_list:\n",
    "            # Ensure 'item' is a dictionary before trying to .get() from it\n",
    "            if isinstance(item, dict):\n",
    "                content = f\"Question: {item.get('question', '')}\\nAnswer: {item.get('answer', '')}\"\n",
    "                faq_data.append(Document(page_content=content, metadata=item))\n",
    "            else:\n",
    "                print(f\"Skipping malformed item in JSON (not a dictionary): {item}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'faq.json' not found. Please create this file with your FAQ content.\")\n",
    "    exit()\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Could not decode 'faq.json'. Please ensure it's a valid JSON file.\")\n",
    "    exit()\n",
    "\n",
    "documents = faq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212bf44c-f253-46c2-bebd-4d8f1a5cc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Split the Documents into Chunks ---\n",
    "# This part remains largely the same, as it operates on LangChain Document objects.\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "634390a1-a5f6-4a30-97dc-7b60684467b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9238b70aeff240078c5892c9a7e8aedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21602f7978b144f287480e57aeeffdb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07434e5948014cf6ae88413a8bbc6c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed6b379111141999042efad03df392f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\FAQ\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\AppData\\Local\\Temp\\fastembed_cache\\models--qdrant--bge-small-en-v1.5-onnx-q. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26771ebb67704eb88777b2035bcb78d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3132b5f05b84f8fa004874a7c565e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-07 15:42:40.655\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mfastembed.common.model_management\u001b[0m:\u001b[36mdownload_model\u001b[0m:\u001b[36m430\u001b[0m - \u001b[31m\u001b[1mCould not download model from HuggingFace: [WinError 1314] A required privilege is not held by the client: '..\\\\..\\\\blobs\\\\0d7726d0cdccb62ee17c03bd1595cff07199b8f8' -> 'C:\\\\Users\\\\hp\\\\AppData\\\\Local\\\\Temp\\\\fastembed_cache\\\\models--qdrant--bge-small-en-v1.5-onnx-q\\\\snapshots\\\\52398278842ec682c6f32300af41344b1c0b0bb2\\\\config.json' Falling back to other sources.\u001b[0m\n",
      "\u001b[32m2025-07-07 15:42:40.655\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mfastembed.common.model_management\u001b[0m:\u001b[36mdownload_model\u001b[0m:\u001b[36m452\u001b[0m - \u001b[31m\u001b[1mCould not download model from either source, sleeping for 3.0 seconds, 2 retries left.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1854f9e3ef4c48978648ce27d58a1811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 4. Create Embeddings and a Vector Store ---\n",
    "embeddings = FastEmbedEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3c91ae-25cd-442d-8cec-b7aff3da81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Build the Conversational Retrieval Chain with Groq ---\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ChatGroq(temperature=0.7, model_name=\"meta-llama/llama-4-scout-17b-16e-instruct\"),\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17488703-aba0-422a-a001-1570e9621399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the FAQ Bot powered by Groq! Ask me anything. Type 'exit' to end.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What payment method is accepted?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Question: What payment methods do you accept?\n",
      "Answer: We accept major credit cards, debit cards, and PayPal as payment methods for online orders.\n",
      "\n",
      "Question: Are my personal and payment details secure?\n",
      "Answer: Yes, we take the security of your personal and payment details seriously. We use industry-standard encryption and follow strict security protocols to ensure your information is protected.\n",
      "\n",
      "Question: Can I order by phone?\n",
      "Answer: Unfortunately, we do not accept orders over the phone. Please place your order through our website for a smooth and secure transaction.\n",
      "\n",
      "Question: Can I request an invoice for my order?\n",
      "Answer: Yes, an invoice is usually included with your order. If you require a separate invoice, please contact our customer support team with your order details.\n",
      "Human: What payment method is accepted?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: We accept major credit cards, debit cards, and PayPal as payment methods for online orders.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Are website is going to save my card details?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: What payment method is accepted?\n",
      "Assistant: We accept major credit cards, debit cards, and PayPal as payment methods for online orders.\n",
      "Follow Up Input: Are website is going to save my card details?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Question: Can I order a product if it is listed as 'discontinued' but still visible on the website?\n",
      "Answer: If a product is listed as 'discontinued' but still visible on the website, it may be an error. Please contact our customer support team for clarification.\n",
      "\n",
      "Question: Are my personal and payment details secure?\n",
      "Answer: Yes, we take the security of your personal and payment details seriously. We use industry-standard encryption and follow strict security protocols to ensure your information is protected.\n",
      "\n",
      "Question: Can I request a product if it is not listed on your website?\n",
      "Answer: If a product is not listed on our website, it may not be available for purchase. We recommend exploring the available products or contacting our customer support team for further assistance.\n",
      "\n",
      "Question: Can I order a product if it is listed as 'on hold'?\n",
      "Answer: If a product is listed as 'on hold,' it is temporarily unavailable for purchase. Please check back later or sign up for notifications when it becomes available.\n",
      "Human: Here is the rephrased standalone question:\n",
      "\n",
      "\"Will your website save my card details?\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Yes, we take the security of your personal and payment details seriously. We use industry-standard encryption and follow strict security protocols to ensure your information is protected.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  How do i need to check wheather product is available or not?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: What payment method is accepted?\n",
      "Assistant: We accept major credit cards, debit cards, and PayPal as payment methods for online orders.\n",
      "Human: Are website is going to save my card details?\n",
      "Assistant: Yes, we take the security of your personal and payment details seriously. We use industry-standard encryption and follow strict security protocols to ensure your information is protected.\n",
      "Follow Up Input: How do i need to check wheather product is available or not?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Question: Can I request a product if it is not currently available in my preferred color?\n",
      "Answer: If a product is not available in your preferred color, it may be temporarily out of stock. Please check back later or sign up for color notifications.\n",
      "\n",
      "Question: Can I order a product if it is listed as 'sold out'?\n",
      "Answer: If a product is listed as 'sold out,' it is currently unavailable for purchase. Please check back later or sign up for notifications when it becomes available again.\n",
      "\n",
      "Question: Can I request a product if it is not listed on your website?\n",
      "Answer: If a product is not listed on our website, it may not be available for purchase. We recommend exploring the available products or contacting our customer support team for further assistance.\n",
      "\n",
      "Question: Can I order a product if it is listed as 'discontinued' but still visible on the website?\n",
      "Answer: If a product is listed as 'discontinued' but still visible on the website, it may be an error. Please contact our customer support team for clarification.\n",
      "Human: Here is the rephrased follow-up question as a standalone question:\n",
      "\n",
      "\"How can I check if a product is available?\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: To check if a product is available, you can:\n",
      "\n",
      "* Check the product's status on our website (e.g., it's listed as 'sold out' or 'discontinued')\n",
      "* Look for a notification or a message indicating that the product is temporarily out of stock or unavailable\n",
      "* Sign up for color notifications or product notifications to be informed when the product becomes available again\n",
      "* Contact our customer support team for further assistance if the product is not listed on our website or if you have any questions about its availability.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Start the Conversation ---\n",
    "chat_history = []\n",
    "print(\"Welcome to the FAQ Bot powered by Groq! Ask me anything. Type 'exit' to end.\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"You: \")\n",
    "    if query.lower() in ['exit', 'quit']:\n",
    "        break\n",
    "\n",
    "    result = qa.invoke({\"question\": query, \"chat_history\": chat_history})\n",
    "    answer = result['answer']\n",
    "\n",
    "    print(f\"Bot: {answer}\")\n",
    "    chat_history.append((query, answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
